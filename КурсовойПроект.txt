    МИНИСТЕРСТВО ОБРАЗОВАНИЯ РЕСПУБЛИКИ БЕЛАРУСЬ
    БЕЛОРУССКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ
    
    ФАКУЛЬТЕТ ПРИКЛАДНОЙ МАТЕМАТИКИ И ИНФОРМАТИКИ
    Кафедра технологий программирования
    
    Применение искусственного интеллекта для разработки компьютерных игр
    
    Курсовой проект

    
    
    
    
    
     
Котусева Дмитрия Дмитриевича
студента 4 курса,
специальность
«Прикладная
информатика»
Научный руководитель:
кандидат физико-математических наук,
доцент В. В. Горячкин



     
     
    Минск - 2019
    

    РЕФЕРАТ
     
    Курсовой проект, 43 с., 43 рис., 7 источников, 2 приложения.
     
    Ключевые слова: АГЕНТ, ИИ, ИГРОВОЙ ДВИЖОК.
    Объект исследования — организация работы искусственного интеллекта в сфере компьютерных игр.
    Предмет исследования — характеристические особенности методов построения эффективной модели игрового искусственного интеллекта.
    Цель работы — исследовать различные схемы работы искусственного интеллекта в играх, адаптировать один из методов при реализации собственного приложения, написать работающий прототип.
    Задачи:
1. аналитический обзор типов компьютерных игр, где применим искусственный интеллект, и способов организации работы искусственного интеллекта;
2. анализ и разбор математических алгоритмов, используемых при разработке искусственного интеллекта;
3. построение собственной модели искусственного интеллекта;
4. разработка работающего прототипа.
    Методы исследования — изучение теоретических материалов, построение логических схем и моделей, проверка теоретических данных в игровом движке.
    Полученные результаты:
1. подготовлен общий аналитический обзор жанров компьютерных игр;
2. проанализированы способы организации игрового искусственного интеллекта, а также используемые при этом алгоритмы;
3. на основе полученных знаний реализован прототип.
    Область применения — компьютерные игры.


    РЭФЕРАТ
     
    Курсавы праект, 43 с., 43 мал., 7 крыніц, 2 прыкладання.
     
    Ключавыя словы: АГЕНТ, ШІ, ГУЛЬНЯВЫ РУХАВІЧОК.
    Аб’ект даследавання — арганізацыя работы штучнага інтэлекту ў сферы кампутарных гульняў.
    Прадмет даследавання — характэрыстычныя асаблівасці метадаў пабудовы эфектыўнай мадэлі гульнявога штучнага інтэлекту.
    Цэль работы — даследаваць розныя формы работы штучнага інтэлекту ў гульнях, адаптаваць адзін з метадаў пры рэалізацыі ўласнага прыкладання, напісаць працуючы прататып.
    Задачы:
1. аналітычны агляд тыпаў кампутарных гульняў, дзе можна прымяніць штучны інтэлект, і спосабаў арганізацыі работы штучнага інтэлекту;
2. аналіз і разбор матэматычных алгарытмаў, выкарыстоўваемых пры распрацоўцы штучнага інтэлекту;
3. пабудова ўласнай мадэлі штучнага інтэлекту;
4. распрацоўка працуючага прататыпу.
    Метады даследавання — вывучэнне тэарэтычных матэрыялаў, пабудова лагічных схем і мадэляў, праверка тэарэтычных даных ў гульнявым рухавічку.
    Атрыманыя вынікі:
1. падрыхтован агульны аналітычны агляд жанраў кампутарных гульняў;
2. прааналізаваны спосабы арганізацыі гульнявога штучнага інтэлекту, а таксама выкарыстаныя пры гэтым алгарытмы.
3. на аснове атрыманых ведаў рэалізаваны прататып.
    Вобласць прымянення — кампутарныя гульні.


    ESSAY
     
    Course project, 43 p., 43 images, 7 sources, 2 appendixes.
     
    Key words: AGENT, AI, GAME ENGINE.
    Object of research — organization of work of artificial intelligence in the field of computer games.
    Subject of research — characteristic features of methods for constructing an effective model of a game artificial intelligence.
    Work purpose — explore different patterns of artificial intelligence development in games, adapt one of the patterns when implementing my own application, develop a working prototype.
    Tasks:
1. analytical review of games where artificial intelligence is used, and ways of organizing artificial intelligence;
2. analysis of mathematical algorithms used in the development of artificial intelligence;
3. building my own model of artificial intelligence;
4. development of a working prototype.
    Research methods — study of theoretical materials, construction of logic circuits and models, checking the theoretical data in the game engine.
    Results:
1. the general analytical review of genres of computer games is prepared;
2. the ways of game artificial intelligence organization are analyzed, as well as the algorithms used in this case;
3. on the basis of the received knowledge the prototype is realized.
    Scope — computer games.


Оглавление
    Введение	7
    1	Игровой искусственный интеллект	10
    1.1	Обзор и классификация технологий и методов искусственного интеллекта	10
    2	Проектирование игрового приложения с искусственным интеллектом	19
    2.1	Обзор современных компьютерных игр и их классификация	19
    2.2	Функциональные и нефункциональные требования	28
    2.3	Алгоритмы для реализации искусственного интеллекта	29
    2.4	Архитектура приложения	42
    3	Реализация искусственного интеллекта в компьютерной стратегии в реальном времени	45
    3.1	Используемые технологии для реализации компьютерной стратегии в реальном времени	45
    3.2	Создание прототипа	45
    Заключение	50
    Список использованных источников	51
    Приложение	52
    

    


Перечень условных обозначений
    ИИ	искусственный интеллект.


Введение
    
    В эпоху стремительно развивающихся информационных технологий достижения прогресса проникают во всё большее количество сфер жизнедеятельности человека. Не исключением стала и индустрия развлечений.
    Мировая индустрия развлечений аккумулирует миллиарды долларов и является значимой частью экономики большинства стран. Она включает большое количество различных направлений, одним из которых является направление компьютерных игр, получившее развитие именно благодаря укреплению в нашей жизни компьютерных технологий.
    Компьютерная игра представляет собой не что иное как обычное приложение, предназначенное для развёртывания на целевой аппаратной платформе. Список этих платформ может варьироваться от обычных в классическом понимании компьютеров до встроенных в автомобили вычислительных устройств и «умных» наручных часов.
    Существует огромное количество самых различных жанров компьютерных игр на любой вкус и цвет: шутеры, симуляторы, стратегии, приключения, музыкальные игры, ролевые игры и др. Стоит отметить, что чётких границ в классификации игр на данный момент не существует и зачастую чётко определить принадлежность игры тому или другому жанру крайне затруднительно.
    Следует понимать, что почти никто из разработчиков игр не начинает разработку своего творения с абсолютного нуля. Все они используют ту или иную стартовую платформу ― игровой движок. Игровой движок выполняет базовые функции, необходимые в любой игре: трёхмерный рендеринг, обработка сигнала устройств ввода-вывода, обработка звуков, отрисовка элементов индикации и т. д. Также он предоставляет разработчикам необходимые программные интерфейсы для взаимодействия со встроенными возможностями движка и организации собственной логики приложения. Таким образом, конечный продукт является результатом работы как создателей движка, так и разработчиков самой игры.
    Как было упомянуто выше, игровые движки берут на себя реализацию базового функционала, без которого никак не обойтись при разработке любой игры. Несмотря на это, на пути создания игры перед разработчиками встаёт немалое количество задач, которые им приходиться решать самим. Одной из таких задач является разработка искусственного интеллекта.
    Стоит отметить, что в рамках игровой индустрии под искусственным интеллектом понимается не аналог интеллекта естественного (интеллекта человека), а его симуляция. Основных причин такого подхода можно выделить три:
1. дороговизна разработки полноценного искусственного интеллекта;
2. нехватка вычислительных мощностей для обеспечения должного уровня игрового опыта для игрока;
3. разработка полноценного искусственного интеллекта зачастую является избыточной в рамках поставленной задачи и обойтись можно куда меньшими силами.
    То есть при разработке игрового искусственного интеллекта перед разработчиками стоит задача наиболее правдоподобной имитации поведения человека с использованием минимального количества вычислительных ресурсов. Реализация искусственного интеллекта сильно влияет на геймплей, системные требования и бюджет игры, и разработчики балансируют между этими требованиями, стараясь сделать интересный и нетребовательный к ресурсам искусственный интеллект малой ценой. Поэтому подход к игровому искусственному интеллекту серьёзно отличается от подхода к традиционному искусственному интеллекту — широко применяются разного рода упрощения, обманы и эмуляции. Например: с одной стороны, в шутерах от первого лица безошибочное движение и мгновенное прицеливание, присущее ботам, не оставляет ни единого шанса человеку, так что эти способности искусственно снижаются. С другой стороны — боты должны делать засады, действовать командой и т. д., для этого применяются «костыли» в виде контрольных точек, расставленных на уровне [2]. В дальнейшем при упоминании искусственного интеллекта будет пониматься именно имитация интеллекта реального, а не его аналог.
    Целью данной работы является изучение и анализ существующих на данный момент методов организации работы искусственного интеллекта, типичных проблем, с которыми сталкиваются разработчики в процессе создания, а также реализация одного или нескольких из них в виде работающего прототипа.
    Актуальность данной работы подкрепляется постоянно растущим спросом игроков на всё более интересные и сложные игры, создание которых требует разработки всё более сложных моделей искусственного интеллекта, а также растущей популярностью компьютерных игр, как способа досуга во всё более широких слоях населения.
    В главе 1 рассматриваются самые распространённые паттерны моделирования игрового искусственного интеллекта.
    В главе 2 происходит разбор существующих игровых жанров, а также алгоритмов, используемых при реализации искусственного интеллекта. Также происходит уточнение и моделирование архитектуры разрабатываемого прототипа.
    Глава 3 содержит в себе описание используемых при разработке технологий и собственно полученные результаты.


1 Игровой искусственный интеллект
1.1 Обзор и классификация технологий и методов искусственного интеллекта
    
    В любой игре, где необходимо наличие искусственного интеллекта (далее ИИ), перед этим ИИ ставится задача по управлению «интеллектуальными агентами», где агент является игровым персонажем, транспортным средством, ботом, а иногда и чем-то более абстрактным: целой группой сущностей или даже цивилизацией. Во всех случаях перед агентом стоят следующие задачи:
• Sense: получить информацию о внешней среде;
• Think: на основе полученных данных принять решение о дальнейших действиях;
• Act: собственно выполнение принятого на предыдущем шаге решения.
    По завершении вышеописанного цикла агент попадёт в новую ситуацию, поэтому цикл придётся проделать заново.
    Существует достаточно большое количество методов (алгоритмов) организации работы ИИ.
    Одним из простейших алгоритмов является дерево решений. Дерево решений состоит из узлов двух типов:
• узлы принятия решений: выбор между двумя альтернативами на основе проверки некоторого условия, где каждая альтернатива представлена в виде отдельного узла;
• конечные узлы: действие для выполнения, представляющее окончательное решение.
    В качестве примера можно провести знаменитую игру Pong, в которой перед игроком и ИИ ставится одинаковая задача — отбить мяч с помощью платформы в сторону оппонента (рисунок 1.1).
    
    
    	
    
    Рисунок 1.1 Интерфейс игры Pong
    Более точно перед ИИ стоит задача ― решить, в каком направлении переместить платформу, чтобы отбить мяч. Блок-схема дерева решений такого ИИ может выглядеть следующим образом (рисунок 1.2):
    
    Рисунок 1.2 Дерево решений для ИИ игры Pong
    В приведённой выше блоке-схеме нетрудно видеть, что получение данных о внешней среде (игра знает, где мяч и где платформа, поэтому ИИ обращается к ней за этой информацией) и принятие решений происходит в узлах принятия решений, выполнение же решений происходит в конечных узлах.
    Дерево решений неплохо подходит для реализаций простых ИИ, способных выполнять небольшой спектр действий. Но иногда существует слишком много условий, чтобы эффективно представить их в дереве решений или скрипте. Иногда нужно заранее оценивать, как изменится ситуация, прежде чем принимать решение о следующем шаге. Для решения этих проблем нужны более сложные подходы [3].
    Ещё одним интересным подходом к организации ИИ является конечный автомат (finite state machine или FSM). Конечный автомат предполагает, что наш агент всегда находится в одном из конечного множества состояний. В качестве примера разберём агента (воина) со следующим конечным автоматом (рисунок 1.3):
    
    Рисунок 1.3 Пример конечного автомата
    
    Рисунок 1.4 Игровой агент
    На рисунке 1.3 нетрудно различить 3 состояния, в которых может находиться агент:
• состояние покоя (именно в нём он находится на рисунке 1.4);
• состояние бега за игроком;
• состояние стрельбы в игрока.
    И снова мы можем посмотреть на эту систему через призму цикла Sense/Think/Act. Sense воплощается в данных, используемых логикой перехода. Think — переходами, доступными в каждом состоянии. А Act осуществляется действиями, совершаемыми периодически в пределах состояния или на переходах между состояниями [3]. Основной вопрос при реализации такой логики ИИ вызывает механизм проверки условий переходов между состояниями. Зачастую логику проверок условий переходов выносят за пределы автомата. Автомат, в таком случае, получает данные условий переходов через обработчики событий, генерируемых внешним кодом. Таким образом, этап Sense происходит вне автомата во внешнем коде.
    Конечно же, описанный выше пример является крайне простым. В более сложных системах количество состояний и связей между ними может значительно возрасти. В этом случае может возникнуть большое количество одинаковых переходов к схожим по логике состояниям. Например, при организации разных типов состояний атаки (атака ближнего боя и стрельба). Автомат такого типа крайне тяжело расширять и отлаживать из-за неоправданно большого количества схожих связей. Решить данную проблему поможет преобразование автомата из обычного одноуровневого в иерархический конечный автомат (hierarchical finite state machine или HFSM), где каждое состояние может быть оболочкой для группы схожих по логике состояний.
    В качестве примера модернизируем автомат нашего воина (рисунки 1.5 и 1.6):
    
    Рисунок 1.5 Верхний уровень иерархического конечного автомата
    
    Рисунок 1.6 Внутренняя логика состояния атаки
    В этом примере мы добавили новый тип атаки (атака ближнего боя) и объединили его вместе с состоянием стрельбы в общее состояние атаки, которое и осталось на верхнем уровне иерархии.
    Таким нехитрым способом возможно минимизировать количество дублированных переходов в конечных автоматах, что значительно улучшает общую расширяемость автомата.
    Ещё одним достаточно популярным методом реализации логики ИИ является дерево поведений (behavior tree). Данный подход стал популярным после успешного его применения в игре Halo.
    В случае дерева поведений логика агента определяется специальным графом, который представляет собой дерево (отсюда первая половина названия метода). Структура графа начинается с единственного корневого узла. В дереве все узлы можно разделить на три типа (рисунок 1.7):
• composite: узлы, имеющие два и более дочерних узлов;
• decorator: узлы, имеющие лишь один дочерний узел;
• leaf: узлы на концах дерева, не имеющие дочерних узлов и обозначающие конкретное действие.
    
    Рисунок 1.7 Структура дерева поведений
    В свою очередь узлы типа composite делятся на два подтипа:
• selector: сигнализирует о том, что только один дочерний узел будет посещён (рисунок 1.8);
• sequence: обеспечивает, что каждый дочерний узел посещается в порядке следования (рисунок 1.9).
    
    Рисунок 1.8 Логика selector’а такова, что он выберет одну из опций в целях утоления голода
    
    Рисунок 1.9 Представлена последовательность действий, которую должен выполнить агент в целях достижения поставленной цели (утоление голода)
    Каждый узел возвращает одно из трёх значений:
• Succeded: действие узла завершилось успешно;
• Failed: действие узла завершилось неудачно;
• Running: узел в данный момент в процессе выполнения.
    Это лишь общая схема работа дерева поведений. Деревья поведений сложны — есть много способов их составить, да и найти правильное сочетание декораторов и составных узлов может быть проблематично [3]. По этой причине существует большое количество всевозможных реализаций данного метода.
    Последним по порядку, но не по значению является алгоритм под общим названием utility-based system (основанная на полезности система). Этот метод предоставляет несколько другой подход к организации выбора решений. Вместо того, чтобы иметь чёткий набор выборов или дерево возможных действий, алгоритм предлагает изучить все действия и выбрать самое подходящее в данный момент на основе какой-либо численной характеристики полезности данного действия, где полезность — произвольная мера того, насколько важно или желательно выполнение этого действия для агента. В общем случае назначается диапазон возможных значений полезности с нижним и верхним пределами. На значение полезностей разных решений могут влиять различные значения внешней среды в данный момент времени. Например, если агент долго не ел и счётчик голода достиг критической отметки, полезность действия «найти пищу» будет стремиться к максимальной из всех возможных. Однако в случае нахождения рядом врагов действие «найти безопасное место» также может заиметь очень высокую меру полезности. Что выберет агент, зависит от реализованной программистом логики, но очевидно, что оба действия в данном примере будут конкурирующими друг с другом и выбор любого из них с точки зрения человека покажется логичным.
    Описанные выше подходы не являются единственными и зачастую могут применяться с некоторыми модификациями. Однако при моделировании и реализации нашего собственного ИИ отталкиваться мы будем именно от них.
    Выводы
    В этой главе были рассмотрены наиболее популярные паттерны организации работы ИИ в компьютерных играх, было получено общее представление, в каких ситуациях тот или иной паттерн может быть более актуальным для использования.


2 Проектирование игрового приложения с искусственным интеллектом
2.1 Обзор современных компьютерных игр и их классификация
    
    Первые компьютерные игры появились лишь в 50-60х годах прошлого столетия, но за это время игровая индустрия совершила огромный скачок в развитии. Очень быстро из каких-то примитивнейших программ игры превратились в произведение искусства [4].
    Как уже говорилось ранее, на сегодняшний день не существует какой-то единой системы классификации. Помимо этого современные игры, как правило, сочетают в себе сразу несколько разнообразных признаков и их с трудом можно оценить в каких-то определённых рамках.
    Естественной обыденностью стала классификация игр по следующим направлениям:
• по платформам, на которые ориентирована игра (игры для настольных компьютеров, для консолей, мобильные игры);
• визуальному представлению (то, как расположена камера, качество графического изображения);
• критериям издателя (инди-игры, free-to-play игры, игры ААА-класса);
• количеству игроков (мультиплеерные и однопользовательские);
• жанрам.
    Наибольший интерес представляет классификация именно по жанрам. Нужно понимать, что классификация игр по жанрам также довольно условна. Во-первых, у многих жанров нет четкого, общепринятого, стандартного определения. Во-вторых, разработчики не прекращают своих экспериментов, разбавляя устоявшиеся типы игровых механик новыми элементами. То есть современные игры могут принадлежать к одному или сразу нескольким жанрам, а то и вовсе представлять собой нечто новенькое [4].
    Однако выделить несколько основных наиболее распространённых жанров вполне возможно. Список этих жанров выглядит следующим образом:
• action;
• RPG;
• simulator;
• strategy.
    Для общего понимания, что из себя представляет каждый из жанров следует более детально разобраться в каждом из них. Пройдёмся по каждому отдельно.
    
    Action
    Данный жанр игр характеризуется быстротой происходящих на экране пользователя событий, необходимостью наличия быстроты реакции и грамотной оценки времени. Он объединяет достаточно широкое семейство игр. Поэтому данный жанр обычно разделяют на несколько подгрупп.
    Первой подгруппой являются шутеры (от английского shooter, то есть стрелок). Их ещё называют симуляторами стрельбы. Шутеры в основном бывают с видом от первого (first person shooter или FPS, рисунок 2.1) или третьего лица (third person shooter или TPS, рисунок 2.2).
    
    Рисунок 2.1 Шутер с видом от первого лица Star Wars Battlefront 2 от Electronic Arts, студия Dice
    
    Рисунок 2.2 Шутер с видом от третьего лица The Division 2 от Ubisoft, студия Massive Entertainment
    Главной целью игрока в шутере является задача перестрелять своего оппонента, будь тот управляемым ИИ агентом или реальным игроком.
    Шутеры являются одним из самых популярных игровых жанров, так как сочетают в себе различные элементы, делающими их привлекательными для практически любой аудитории.
    Помимо шутеров в жанр action также входят и файтинги (от английского fighting, то есть сражение). Если в шутерах перед игроком стоит задача расправиться с достаточно обширным количеством оппонентов с помощью огнестрельного оружия, то в файтингах игроку предстоит сражаться, как правило, с одним, реже несколькими оппонентами в ближнем бою (рисунок 2.3).
    
    Рисунок 2.3 Классический пример файтинга ― серия игр Mortal Combat. Выше представлен скриншот Mortal Combat 11 от WB Games, студия NetherRealm Studios
    Ещё одним подтипом жанра action являются слешеры (от английского slasher). Slasher в переводе с английского языка означает «искромсать», «рубить», что в точности описывает основное действо, совершаемое героем слэшера на протяжении всей игры. Основная задача персонажей игр такого жанра заключается в истреблении огромного количества врагов с помощью холодного клинкового оружия (рисунок 2.4) [4].
    
    Рисунок 2.4 Слешер Devil May Cry 5 от Capcom
    Последними из основных подтипов жанра action являются платформеры. Из названия вытекает основное отличие данного подтипа ― наличие в нём платформ. Платформы — это самые разнообразные опоры, вроде островков земли, повешенных в воздухе или этажей дома. Цель игрока в платформере ― добраться от начала уровня в его конец, преодолевая препятствия. Как правило, герою платформера необходимо часто совершать прыжки, чтобы преодолевать пропасти, обрывы, двигаясь от платформы к платформе. Помимо преодоления препятствий, от игроков нередко требуется уничтожать врагов (зачастую наскоком) и собирать предметы (рисунок 2.5) [4]. 
    
    Рисунок 2.5 Платформер Sonic Lost World от Sega и Nintendo, студии Sonic Team и Dimps
    RPG
    RPG или role playing game жанр концентрирует внимание игрока на сюжете игры и развитии одного или нескольких персонажей в контексте этого сюжета. Игрок выбирает путь развития своего персонажа по мере прохождения сюжета, прокачивая его навыки и умения. Нередко в играх такого жанра игроку даётся возможность повлиять на ход сюжета, давая ему возможность выбора в ключевых точках повествования. Зачастую игры RPG-жанра имеют признаки других жанров, например, очень распространены action-RPG, сочетающие в себе черты как RPG, так и action (рисунок 2.6).
    
    Рисунок 2.6 Action-RPG игра Mass Effect 3 от Electronic Arts, студия BioWare
    Simulator
    Игры жанра «симулятор» симулируют реальность, иначе говоря, пытаются помочь игроку воспроизвести какой-либо реальный опыт [4]. Подкатегорий у симуляторов огромное множество, начиная от симуляторов лётчиков гражданской авиации и заканчивая спортивными и гоночными симуляторами (рисунок 2.7).
    
    	Рисунок 2.7 Футбольный симулятор FIFA 19 от Electronic Arts
    Также существует подкатегория аркадных симуляторов с уменьшенной степенью реализма в угоду более увлекательному игровому опыту (рисунок 2.8).
    
    Рисунок 2.8 Аркадный гоночный симулятор Need for Speed: Payback от Electronic Arts, студия Ghost Games
    Strategy
    Последним жанром в нашем списке являются стратегии. Игры данного жанра характеризуются тем, что игроку для достижения цели необходимо применять стратегическое мышление, и оно противопоставляется быстрым действиям и реакции, которые, как правило, не обязательны для успеха в таких играх (однако есть исключения) [5]. Также в стратегических играх игрок, как правило, как бы отстранён от игрового мира и наблюдает со всем со стороны, отдавая приказы подчинённым ему юнитам.
    Стратегии прежде всего принято классифицировать по ходу времени. По этому признаку выделяют следующие типы стратегий:
• стратегии в реальном времени или RTS (Real Time Strategy);
• пошаговые стратегии или TBS (Turn Based Strategy);
• гибридные варианты описанных выше типов.
    Начнём разбор с пошаговых стратегий, так они хронологически появились раньше остальных.
    Пошаговые стратегии — игры, в которых игроки производят свои действия по очереди. Пошаговые стратегии появились раньше RTS и отличаются значительно большим разнообразием. Разделение игрового процесса на ходы отрывает его от реальной жизни и лишает игру динамизма, в результате чего эти игры не так популярны, как стратегии в реальном времени. С другой стороны, в TBS у игрока гораздо больше времени на размышление, во время совершения хода его ничто не торопит, что позволяет уделять больше времени планированию (рисунок 2.9) [5].
    
    Рисунок 2.9 Пошаговая тактическая стратегия XCOM 2 от 2K Games, студия Firaxis Games
    Следующими по списку идут гибридные стратегии. Необходимость их появления была обусловлена тем, что в своё время на волне коммерческого успеха пошаговых стратегий (Empire, King`s Bounty, Warlords, SimCity, Civilization, Heroes of Might and Magic) разработчики хотели дать возможность игрокам померяться силами с другими игроками, а не только с ИИ. Код таких игр как Civilization и Heroes of Might and Magic переделывали для возможности игры вдвоем [5]. Но тут всплыла главная проблема концепции пошаговых стратегий: необходимость ожидать окончания хода других игроков. В итоге один ход всех игроков мог растянуться на целый час и более. Ограничение ходов по времени также не сильно помогало, так как, например, даже ограничение хода в 5 минут для четырёх игроков выливалось в среднее время хода около 15-20 минут. Было ясно, что концепция пошаговых стратегий никак не стыкуется с возможностью мультиплеера. Возникновение гибридных стратегий решило эту проблему.
    Основная идея гибридных стратегий такова, что игроки вместо поочерёдных ходов совершают ходы одновременные. После окончания ходов всех игроков игра их обрабатывает и переходит к следующему. На ходы также накладывается ограничение по времени, поэтому каждый ход всех игроков не превышает какой-то фиксированный величины времени (рисунок 2.10). Стоит отметить, что решение проблемы величины времени ходов, присущее гибридным стратегиям,  ― это, по сути, всё, что отличает их от пошаговых аналогов. Все современный игры, использующие пошаговые механики, для мультиплеера использует гибридный подход. Поэтому понятие гибридности для таких игр применяется крайне редко и их, так же как и пошаговые (в классическом смысле) стратегии, называют пошаговыми.
    
    Рисунок 2.10 Гибридная стратегия Age of Wonders 3 от Triumph Studios
    Последними в списке идут стратегии в реальном времени. Игроки совершают свои действия одновременно без деления временных промежутков на ходы. Иначе говоря, игровой процесс обладает свойством непрерывности, а не дискретности (как в пошаговом случае). В настоящее время жанр стратегий в реальном времени стал весьма широк и включает игры совершенно разного типажа – от тактических варгеймов до глобальных стратегий (рисунок 2.11) [5].
    Помимо классификации по времени есть ещё целое множество различных способов классифицировать стратегии, но все они ориентируются уже, как правило, на сравнение игрового сеттинга, мелких особенностей реализации и наполнения игр, а не на принципиальные подходы к построению игровых механик.
    
    Рисунок 2.11 RTS Men of Wat Assault Squad 2 от 1C Company, студия Digitalmindsoft
    Заключение
    В заключение, хочется ещё раз отметить, что в наше время «чистых» представителей какого-либо жанра отыскать практически невозможно и даже приведенные выше примеры вполне могут соответствовать и другим, помимо основного, жанрам.
    Также нельзя не заметить, что помимо упомянутых выше жанров есть и другие менее распространённые, однако от этого не менее популярные, упоминание которых было решено опустить, так как подробный обзор всех существующих жанров не является основной целью данной работы.
    
2.2 Функциональные и нефункциональные требования
    
    Мы рассмотрели основные жанры компьютерных игр. При разработке собственного прототипа мы в первую очередь будем ориентироваться на стратегии в реальном времени, так как именно в играх этого жанра влияние ИИ на общий игровой опыт пользователя особенно велико.
    Выделим следующие наиболее важные функциональные требования к разрабатываемому прототипу:
• Возможность отдавать приказы подчинённым игроку игровым агентам;
• Способность ИИ выполнять простые действия типа атаки противника в радиусе действия, помощи союзным агентам, находящимся поблизости, и т. д.;
• Возможность поставить игру на паузу в любой момент времени;
• Наличие разнородной игровой локации, где агенты смогут в полной мере проявить свои интеллектуальные качества;
• Наличие возможности покинуть и перезапустить игру.
    Главными же нефункциональными требованиями к прототипу являются быстрая скорость работы логики каждого агента, а также хорошая расширяемость программного кода для возможности последующего добавления нового функционала.
    
2.3 Алгоритмы для реализации искусственного интеллекта
    
    Первым вопросом, который стоит перед разработчиками почти любого искусственного интеллекта, является вопрос навигации агента в игровом пространстве.
    И вправду игровой опыт пользователя от игры, в которой боты не способны элементарно передвигаться, скорее всего будет негативным, особенно когда речь идёт об играх с открытым миром.
    Steering behaviors
    В самых простых случаях, когда игровое пространство представляет собой открытую локацию с минимальным количеством препятствий, используют подход, называемый steering behaviors.
    Steering behaviors помогают автономным персонажам реалистично двигаться благодаря применению простых сил, сочетание которых создаёт естественно выглядящее и импровизированное движение по окружению [6].
    Принцип данного подхода основан на законах векторной математики и во многом сводится именно к сложению и вычитанию векторов.
    Концепция steering behaviors подразумевает наличие нескольких стандартных паттернов логики перемещения агента в пространстве, но каждый из них основывается на плавном изменении вектора скорости объекта под действием управляющих сил и последующем применении изменённого вектора скорости при вычислении следующей позиции объекта. Понятно, что каждый агент в такой системе должен обладать параметрами текущей позиции и скорости, оба из который представляют собой векторы (рисунок 2.12).
    
    Рисунок 2.12 Тут вектор P ― вектор позиции (координаты пространства интерпретируются как векторы), а вектор V ― вектор скорости
    Seek
    Первым паттерном является паттерн поведения seek (переводится как стремиться). Использование данного паттерна подразумевает наличие цели, к которой движется (стремится) агент.
    В случае поведения seek добавление персонажу в каждом кадре управляющих сил заставляет его плавно менять скорость, избегая резких смен маршрута. Если цель сдвигается, то персонаж будет постепенно изменять свой вектор скорости, пытаясь добраться до цели в её новом местоположении.
    В поведении seek задействуются два вектора: требуемая скорость и управляющая сила (рисунок 2.13) [6]:
    
    Рисунок 2.13 Current velocity ― текущая скорость объекта, desired velocity ― требуемая скорость объекта, steering ― управляющая сила
    Требуемая скорость ― это та скорость, к которой стремится прийти агент. В этом и всех последующих паттернах данное понятие будет присутствовать. По сути своей, требуемая скорость представляет собой вектор той скорости, имея который агент достигнет цели за минимальное время.
    Если бы мы просто присваивали требуемую скорость скорости агента, то это бы выглядело нереалистично (агент мгновенно меняет направление) и сказалось бы на игровом опыте пользователя.
    Итак, общая логика паттерна seek такова: каждый кадр мы высчитываем вектор управляющей силы:
    steering = desired_velocity - velocity,				(2.1)
    где
    steering ― вектор управляющей силы;
    desired_velocity ― требуемый вектор скорости объекта;
    velocity ― текущая скорости объекта.
    В процессе игры текущая скорость агента как правило храниться в поле одного из соответствующих агенту классов. А вот требуемую скорость нужно каждый кадр пересчитывать, так как движение объекта в пространстве сводит на ноль актуальность рассчитанной в прошлом кадре требуемой скорости.
    Вектор требуемой скорости высчитывается по следующей формуле:
    desired_velocity = (target - position).normalized * required_magnitude, (2.2)
    где
    desired_velocity ― требуемый вектор скорости объекта;
    target ― вектор координат цели;
    position ― вектор координат агента;
    required_magnitude ― величина требуемой скорости, скаляр.
    В формуле (2.2) проводится операция нормализации разности векторов target и position (запись .normalized) для того, чтобы подсчитанный вектор требуемой скорости не зависел от дистанции между агентом и целью. Этот приём в дальнейшем будет использован не единожды.
    С помощью формул (2.1) и (2.2) можно подсчитать вектор управляющей силы, остаётся только приложить его к текущей скорости:
    velocity = truncate(velocity + steering * delta_time, max_speed),	(2.3)
     где
    velocity ― скорость агента;
    steering ― вектор управляющей силы;
    delta_time ― время, прошедшее между кадрами, скаляр;
    max_speed ― максимальная величина вектора скорости, скаляр.
    Операция truncate обеспечивает, что величина вектора velocity не превысит значения max_speed. Домножение на delta_time необходимо для обеспечения независимости быстроты изменения скорости от частоты кадров в игре (без этого на высокопроизводительных системах агент будет передвигаться куда быстрее, чем на малопроизводительных). Помимо delta_time также возможно домножить steering на какой-либо масштабирующий коэффициент (константу), таким образом регулируя скорость поворотов.
    После вычисления текущей скорости мы готовы вычислить новую координату агента:
    position = position + velocity * delta_time,			(2.4)
    где
    position ― координата агента;
    velocity ― текущая скорость;
    delta_time ― время, прошедшее между кадрами.
    Общая схема движения агента к цели с использованием seek поведения представлена на рисунке 2.14.
    
    Рисунок 2.14 Оранжевым цветом помечена траектория движения агента к цели (seek path)
    Flee
    Поведение flee (убегание) является противоположным по отношению к seek. Тут агент уже не стремится достигнуть цели, а наоборот отдалиться от неё как можно дальше. Иными словами, если в случае seek вектор desired_velocity был направлен в сторону цели, то теперь он направлен от неё (рисунок 2.15).
    
    Рисунок 2.15 Логика паттерна flee
    В виде формуле это свойство можно записать так:
    flee_desired_velocity = -seek_desired_velocity,		(2.5)
    где
    flee_desired_velocity ― вектор требуемой скорости убегания;
    seek_desired_velocity ― вектор требуемой скорости стремления к цели.
    Учитывая, что seek_desired_velocity вычисляется по формуле (2.2), формулу (2.5) можно переписать:
    desired_velocity = (position - target).normalized * required_magnitude, (2.6)
    где
    desired_velocity ― требуемый вектор скорости убегания объекта;
    target ― вектор координат цели;
    position ― вектор координат агента;
    required_magnitude ― величина требуемой скорости, скаляр.
    Все остальные формулы паттерна flee полностью совпадают с flee.
    Arrival
    Поведение seek заставляет персонаж двигаться к цели. Когда он достигает своей цели, управляющая сила продолжает на него воздействовать в соответствии с теми же правилами, заставляя персонаж «скакать» вперёд и назад вокруг цели. Поведение же arrival помогает успешно бороться с этой проблемой. При приближении к конечной точке оно позволяет плавно останавливаться вплоть до полной остановки в точке назначения.
    Общая схема поведения состоит из двух этапов:
1. Сначала, когда агент находится на большом расстоянии от цели, он движется по паттерну seek.
2. Когда агент подходит достаточно близко к цели (внутри области замедления), он начинает снижать скорость до полной остановки (рисунок 2.16).
    
    Рисунок 2.16 Длина зелёного вектора скорости отражает величину скорости агента в каждой точке
    То есть, по сути, перед нами стоит задача высчитать вектор управляющей силы замедления, который должен зависеть от дистанции до цели в радиусе замедления. Логично, что, находясь в позиции цели, агент должен иметь скорость ноль, то есть управляющая сила должна по модулю быть равной его текущей скорости, чтобы при очередном вычислении скорости обнулить её. 
    desired_velocity = (target – position).normalized * required_magnitude * (distance / slowing_radius),								   (2.7)
    где
    desired_velocity ― вектор требуемой скорости;
    target ― вектор позиции цели;
    position ― вектор позиции агента;
    required_magnitude ― величина требуемой скорости без учёта замедления, скаляр;
    distance ― расстояние от агента до цели;
    slowing_radius ― дистанция замедления.
    Данная формула применяется тогда, когда агент находится в зоне замедления, то есть подошёл достаточно близко (distance <= slowing_radius). Иначе используется стандартная формула поведения seek.
    Далее вычисляется значение управляющей силы по уже описанной формуле (2.1).
    Нетрудно видеть, что величина управляющей силы в случае прибытия агента в точку назначения будет равна величине скорости по модулю и противоположно ей направлена, то есть итоговая скорость после воздействия на неё управляющей силы будет равна нулю. Именно этого мы и добивались.
    В конечном итоге, паттерн arrival можно рассматривать как более универсальное продолжение паттерна seek.
    Wander
    Паттерн wander (блуждать) подразумевает случайное блуждание персонажа по какой-либо территории. Если игрок увидит чётко заданные маршруты или нереалистичное перемещение, то это приведёт к раздражению. В самом худшем случае игрок поймёт, как предсказывать движения персонажа, и тогда игровой процесс станет для него скучным. Управляющее поведение wander предназначено для создания реалистичного «естественного» движения, которое убедит игрока, что персонаж на самом деле живой и самостоятельно ходит [6].
    Существует достаточно большое множество различных реализаций этого паттерна. Самым простым из них является использование паттерна seek в связке с периодическим заданием новой точки назначения.
    Pursuit
    При использовании паттерна pursuit агент стремиться догнать движущуюся в пространстве цель. Его отличие от паттерна seek состоит в том, что агент пытается предугадать будущую позицию цели и направляется именно к ней (рисунок 2.17).
    
    Рисунок 2.17
    Для предугадывания будущей позиции цели используется немного изменённая формула (2.4):
    future_position = position + velocity * T,			(2.8)
    где
    future_position ― предполагаемая координата цели в будущем;
    position ― текущая координата цели;
    velocity ― текущая скорость цели;
    T ― время от текущего момента времени, на которое производится предугадывание.
    Параметр T в формуле (2.8) обычно подсчитывают динамически, при этом он должен зависеть от скорости цели и дистанции от цели до агента:
    T = distance_between_target_and_pursuer / max_velocity,	(2.9)
    где
    T ― время от текущего момента времени;
    distance_between_target_and_pursuer ― дистанция между целью и агентом;
    max_velocity ― максимальная скорость цели.
    Данный трюк необходим для актуализации вычисляемой координаты цели в будущем (абсурдно считать позицию цели в далёком будущем, находясь к ней очень близко).
    В остальном же движение к вычисленной будущей позиции цели происходит по паттерну seek.
    Evade
    Поведение Evade противоположно поведению Pursuit. Вместо стремления к будущей позиции цели при поведении Evade будет убегать от этой позиции (рисунок 2.18) [6]:
    
    Рисунок 2.18
    Для удаления от цели в этом случае используется паттерн flee.
    Комбинирование паттернов
    Элегантность steering behaviors заключается в том, что все вышеописанные паттерны можно легко комбинировать. Например, если агент должен одновременно достичь какой-либо цели, но в то же время убежать от другого агента. В этом случае напрашиваются паттерны seek и evade. Для применения обоих паттернов одновременно нужно просто вычислить значения управляющих сил для каждого из паттернов и сложить их. Полученный вектор необходимо промасштабировать и применить к скорости по уже известной формуле (2.3).
    Алгоритмы поиска наикратчайшего пути
    Описанные выше паттерны позволяют агентам реалистично передвигаться в пространстве, используя простые правила векторной математики. Однако для более сложных систем такого подхода будет недостаточно. Например, пользователь, приказав агенту двигаться в определённую точку локации, на пути к которой будет много препятствий, ожидает нахождения агентом минимального по длине маршрута к этой цели, чего простые steering behaviors в чистом виде обеспечить не могут. Тут нам на помощь приходят алгоритмы поиска кратчайшего пути на графах.
    Для использования алгоритмов поиска на графах на игровые локации обычно помещает сетки возможных путей (путей, по которым может пройти агент). Они визуально представляют собой ни что иное как граф (рисунок 2.19).
    
    Рисунок 2.19 Простейший пример путевой сетки (визуализирована для наглядности, в процессе игры игроки её, как правило, не видят)
    Таким образом, агент при ориентации в пространстве видит карту именно как набор узлов, связанных между собой рёбрами. В английской литературе такая организация взаимодействия агентов с миром называется просто waypoints (путевые точки, рисунок 2.20).
    
    Рисунок 2.20 Красные шары – визуализированные waypoint’ы
    Более продвинутой версией путевых точек является так называемый навигационный меш (navigation mesh). Навигационный меш представляет собой набор двухмерных полигонов, обозначающих зоны, по которым агент может передвигаться. Переходя на язык графов, по сути, каждый полигон является узлом графа, в котором производится поиск пути (рисунок 2.21).
    
    Рисунок 2.21 Синим цветом нарисован навигационный меш, в котором легко различимы полигоны ― составные части меша
    Мы определились, каким образом представить игровое окружение для агента в понятном ему виде. Но теперь возникает вопрос, каким же образом найти кратчайший путь.
    Конечно, при поиске кратчайшего пути в графе первыми приходят на ум:
1. Алгоритм поиска в ширину;
2. Алгоритм Дейкстры.
    Каждый из них неплохо себя показывает в определённых ситуациях, однако алгоритм поиска в ширину хорош тогда, когда не нужно учитывать стоимость перехода из узла в узел, а алгоритм Дейкстры в чистом виде редко когда применяется. Применяется именно модифицированная версия алгоритма Дейкстры, называемая A*.
    Разберём принцип работы алгоритма A*.
    Напишем функцию, реализующую алгоритм A*, с помощью псевдокода.
     // Функция принимает в качестве параметров текущее положение агента
     // и конечное положение цели, а также сам граф поиска
     function AStarAlgorithm(start, finish, graph):
     	// Приоритетная очередь ещё не посещённых вершин
      PriorityQueue frontier = new PriorityQueue()
      // В приоритетную очередь кладётся стартовая позиция агента
      // Вторым параметром является вес данной позиции в очереди
      // Чем ниже вес, тем выше приоритет
      Frontier.Put(start, 0 + HeuristicFunc(start, finish))
      // Контейнер для хранения узлов, из которых был достигнут
      // данный узел
      Map cameFrom = newMap()
      cameFrom[start] = null
      // Контейнер для хранения цен, за которые были достигнуты
      // узлы
      Map costSoFar = newMap()
      costSoFar[start] = 0
      while (frontier.NotEmpty())
      	current = frontier.Get()
      	frontier.Pop()
        	if (current == finish)
            		break
      	for neighbor in graph.Neighbors(current)
newCost = costSoFar[current] + graph.Cost(current, neighbor)
if neighbor not in costSoFar or newCost < costSoFar[neighbor]:
               			costSoFar[neighbor] = newCost
priority = newCost + HeuristicFunc(finish, neighbor)
               			frontier.Put(neighbor, priority)
               			cameFrom[neighbor] = current
     	// Если конечного узла нет в этой коллекции, значит конечный узел
     	// не достижим из заданной начальной точки
      if (finish not in cameFrom)
     		return null
     	// Осталось построить путь к цели, который и будет возвращён
     	// в качестве результата. Для этого используется коллекция
     	// cameFrom
     	List resultPath = new List()
     	current = finish
      while (current != start)
      	resultPath.PushBack(current)
      	current = cameFrom[current]
      return resultPath
    Алгоритм A* очень похож на алгоритм Дейкстры и почти вся его суть в точности копирует алгоритм Дейкстры, поэтому его можно смело назвать модификацией алгоритма Дейкстры. Основное же отличие от алгоритма Дейкстры состоит в том, что нужно найти один путь до одной конкретной вершины, в то время как алгоритм Дейкстры ищет кратчайшие пути сразу ко всем вершинам графа. Конечно, можно, используя алгоритм Дейкстры, останавливать поиск, когда мы дойдём до нужной нам вершины, после чего восстановить путь именно до неё, и получить тот же самый результат, что и при использовании алгоритма A*, однако тут сказывается второе отличие алгоритма A* от алгоритма Дейкстры ― наличие эвристической функции (в псевдокоде называется HeuristicFunc).
    Эвристическая функция, так сказать, помогает задать направление поиска. Реализация эвристической функции не фиксирована строго. Однако зачастую эвристическая функция оценивает расстояние до цели:
    function HeuristicFunc (a, b):
    	return Sqrt(Pow(a.x - b.x, 2) + Pow(a.y - b.y, 2) + Pow(a.z - b.z, 2))
    На рисунках 2.22 и 2.23 наглядно показана разница результатов работы алгоритмов Дейкстры и A*.
    
    Рисунок 2.22
    
    Рисунок 2.23
    Нетрудно видеть, что, обеспечивая тот же результат что и алгоритм Дейкстры, алгоритм A*, перебирает куда меньше узлов, таким образом ускоряя общую скорость работы алгоритма, что может быть критически важно, когда в игровом пространстве находится сразу множество агентов, для каждого из которых нужно быстро посчитать путь до цели.
    
2.4 Архитектура приложения
    
    Для реализации стратегии в реальном времени при построении логики игровых агентов на текущем этапе было решено использовать концепцию конечных автоматов с некоторыми модификациями. А именно в общем случае у агента есть поле, содержащее его текущую цель, которая также может и отсутствовать. Отсутствие цели соответствует состоянию покоя (idle). Во время игры агент пытается выполнить поставленную задачу. В рамках этого проекта было принято решение для выполнения каждой цели задать строго определённую последовательность действий, что сводит текущую архитектуру именно к архитектуре конечных автоматов, где каждая цель соответствует определённому автомату. Однако, при последующей разработке, если дать агенту право выбирать последовательность наиболее актуальных действий для выполнения цели, такая архитектура уже будет больше напоминать своими чертами GOAP (более сложная система управления поведением агентов, не рассмотренная в этой работе).
    Была спроектирована общая схема конечного автомата (рисунок 2.24).
    
    Рисунок 2.24 Конечный автомат игрового агента
    Приведенный выше автомат состоит из двух основных состояний, каждому из которых соответствует своя цель. Цель движения соответствует состоянию moving, а idle-состояние агента связано с отсутствием текущей цели. Замечу, что в idle-состоянии агент с определённой заданной частотой производит поиск врагов в радиусе видимости и пытается их атаковать с места, что соответствует подсостоянию attack. 
    При моделировании классов была получена следующая диаграмма (рисунок 2.25):
    
    Рисунок 2.25 Основные смоделированные классы
    В этой системе классов ключевое значение имеют три сущности:
• сущность Controller, от лица которой выступает либо игрок, либо ИИ, в рамках этого проекта будет реализован только PlayerController, то есть Controller от лица игрока;
• сущность Agent, олицетворяющая в данной ситуации управляемого агента со всеми вспомогательными и необходимыми для корректной работы классами;
• сущность PoolSystem, выполняющая роль хранилища быстрого доступа для всех элементов игры, используемых часто и имеющих короткий срок жизни. Эта сущность оберегает нас от лишних потерь производительности при повторном освобождении и выделении памяти.
    Выводы
    В главе 2 были рассмотрены основные жанры современных компьютерных игр, были заданы функциональные и нефункциональные требования к разрабатываемому прототипу. Также были изучены алгоритмы, используемые при реализации игрового ИИ. Была задана базовая архитектура приложения.


3 Реализация искусственного интеллекта в компьютерной стратегии в реальном времени
3.1 Используемые технологии для реализации компьютерной стратегии в реальном времени
    
    Для реализации компьютерной стратегии в реальном времени было принято решение использовать игровой движок Unity, который можно легко скачать с официального сайта бесплатно.
    Целевой платформой для игры будут персональные компьютеры, так как именно они обеспечивают достаточное количество устройств ввода для приемлемого уровня управления в игре в отличие от консолей или мобильных устройств.
3.2 Создание прототипа
    
    Для разработки и тестирования функционала прежде всего необходима подходящая игровая локация (рисунок 3.1):
    
    Рисунок 3.1 Игровая локация
    Далее с помощью программы Blender была разработана игровая модель персонажа, после чего она был успешно импортирована в Unity (рисунки 3.2 и 3.3)
    
    Рисунок 3.2 Модель персонажа в Blender
    
    Рисунок 3.3 Модель персонажа в Unity
    Так же была добавлена модель винтовки из открытых источников (рисунок 3.4):
    
    Рисунок 3.4 Модель винтовки M16
    Завершённый настроенный агент выглядел так (рисунок 3.5):
    
    Рисунок 3.5 Завершенные агенты зелёной команды
    Также было разработано меню для запуска игры и меню для паузы (рисунки 3.6 и 3.7):
    
    Рисунок 3.6 Меню входа в игру
    
    Рисунок 3.7 Меню паузы
    Агенты были разделены на две команды: зелёные и жёлтые. Агенты из зелёной команды атаковали агентов из жёлтой и наоборот.
    В процессе игры агенты неплохо показали себя во время боя со своими оппонентами, выбирая самые приоритетные цели, оценивая дальность до цели и видимость наиболее уязвимых мест (рисунки 3.8 и 3.9):
    
    Рисунок 3.8
    
    Рисунок 3.9
    


Заключение
    
    В ходе работы были рассмотрены основные жанры компьютерных игр. Также были изучены наиболее популярные подходы к организации искусственного интеллекта.
    Был написан прототип приложения в жанре стратегии в реальном времени с использованием искусственного интеллекта, чья логика была построена на концепции конечных автоматов.
    Игровая индустрия с каждым годом набирает всё большие обороты. Всё больше людей начинают рассматривать игры как увлекательное время досуга. Перед разработчиками встают всё более сложные задачи по проектированию ИИ таким образом, чтобы даже бывалому игроку было нескучно играть в очередное их творение. Это и обуславливает значимость и актуальность данной работы.
    В рамках дипломной работы предстоят следующий задачи:
• расширение спектра поведений агентов;
• создание AIController, который будет управлять ботами от лица ИИ;
• добавление мультиплеера;
• расширение спектра доступного оружия;
• оптимизация работы приложения.


Список использованных источников
    
1. Классификация компьютерных игр [Электр. ресурс] ― https://ru.wikipedia.org/wiki/%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F_%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D1%8B%D1%85_%D0%B8%D0%B3%D1%80
2. Игровой искусственный интеллект [Электр. ресурс] ―  https://ru.wikipedia.org/wiki/%D0%98%D0%B3%D1%80%D0%BE%D0%B2%D0%BE%D0%B9_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82
3. Как создать игровой ИИ: гайд для начинающих [Электр. ресурс] ―  https://habr.com/ru/company/pixonic/blog/428892/
4. Описание игровых жанров [Электр. ресурс] ― http://app-s.ru/index/genres_of_games/0-52
5. Компьютерная стратегическая игра [Электр. ресурс] ― https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D1%82%D0%B5%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%B8%D0%B3%D1%80%D0%B0
6. Имитация естественного движения: Steering Behaviors. ― Fernando Bevilacqua [Электр. ресурс] ― https://habr.com/ru/post/358366/
7. Введение в алгоритм A* [Электр. ресурс] ―  https://habr.com/ru/post/331192/


Приложение A
    
    Исходный код класса Health:
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using Sirenix.OdinInspector;

/// <summary>
/// Responsible for managing health and death of agent
/// </summary>
public class Health : MonoBehaviour
{
    [SerializeField]
    [Min(1)]
    float maxhealthPoints = 100;
    public float MaxhealthPoints
    {
        get
        {
            return maxhealthPoints;
        }
    }

    [SerializeField]
    float healthPoints = 100;

    [SerializeField]
    [Required]
    DeathManager deathManager;

    [SerializeField]
    [Required]
    Unit unit;

    public float HealthPoints
    {
        get
        {
            return healthPoints;
        }
    }

    public void ChangeHealthPoints(float changeAmount, Collider hitedCollider = null)
    {
        float resultChangeAmount = changeAmount;
        if (hitedCollider != null)
        {
            float multiplier = unit.GetHitColliderCost(hitedCollider);
            resultChangeAmount *= multiplier;
        }
        healthPoints = Mathf.Clamp(healthPoints + resultChangeAmount, 0, maxhealthPoints);

        if (healthPoints == 0)
        {
            Die();
        }
    }

    public void Die()
    {
        deathManager.Die();
    }
}

    Исходный код класса Agent:
using System.Collections;
using UnityEngine;
using Sirenix.OdinInspector;
using Pathfinding;
using System;

public class Agent : MonoBehaviour
{
    [BoxGroup("Projectors")]
    [SerializeField]
    [Tooltip("Projector used to highlight if unit is in selection list")]
    GameObject selectionProjector;

    [BoxGroup("Projectors")]
    [SerializeField]
    [Tooltip("Projector used to highlight if unit is main in selection list")]
    GameObject mainSelectionProjector;

    [BoxGroup("Settings")]
    [SerializeField]
    [Tooltip("Agent's look distance")]
    float lookDistance = 60f;

    [SerializeField]
    [Tooltip("Controller that is able to give commands to this unit")]
    Controller controller;

    [SerializeField]
    [Tooltip("AI path handler")]
    RichAI aiPathHandler;

    [SerializeField]
    AgentWeaponManager weaponManager;

    [SerializeField]
    EyeSightManager eyeSightManager;

    [SerializeField]
    SoldierBasic soldierBasic;
    public SoldierBasic SoldierBasic
    {
        get
        {
            return soldierBasic;
        }
    }

    private Formation currentFormation = null;

    private Goal currentGoal = null;

    // Moving goal additional help variables
    #region
    private Coroutine checkEndPathCoroutine = null;
    private Vector3 previosCheckCoordinate = new Vector3(Mathf.Infinity, Mathf.Infinity, Mathf.Infinity);
    #endregion

    /////////////Idle behavior//////////
    [BoxGroup("Idle behaivor settings")]
    [SerializeField]
    private float checkForCloseEnemyWhenThereIsTargetPeriod = 2f;
    [BoxGroup("Idle behaivor settings")]
    [SerializeField]
    private float checkForCloseEnemyWhenThereIsNoTargetPeriod = 0.5f;
    private Coroutine checkForCloseEnemyWhenThereIsTarget = null;
    private bool isCheckForEnemyWhenThereIsTargetTurnedOn = false;
    private Coroutine checkForCloseEnemyWhenThereIsNoTarget = null;
    private bool isCheckForEnemyWhenThereIsNoTargetTurnedOn = false;
    private Transform currentEnemyUnitBodyPart = null;
    ////////////////////////////////////

    // Getters and setters
    #region
    public float AgentRadius
    {
        get
        {
            return aiPathHandler.radius;
        }
    }

    public void SetController(Controller controller)
    {
        this.controller = controller;
    }

    public Controller GetController()
    {
        return controller;
    }

    public void SetCurrentFormation(Formation currentFormation)
    {
        this.currentFormation = currentFormation;
    }

    public Formation GetCurrentFormation()
    {
        return currentFormation;
    }

    public void ClearCurrentFormation()
    {
        currentFormation = null;
    }

    public void SetNewGoal(Goal newGoal)
    {
        if (currentGoal == null)
        {
            CleanUpIdleStateVariables();
        }

        currentGoal = newGoal;

        if (currentGoal is MoveGoal)
        {
            aiPathHandler.destination = (currentGoal as MoveGoal).Destination;
            aiPathHandler.isStopped = false;

            checkEndPathCoroutine = StartCoroutine(CheckEndPathAsync());
        }
    }

    private void CleanUpIdleStateVariables()
    {
        if (checkForCloseEnemyWhenThereIsTarget != null)
        {
            StopCoroutine(checkForCloseEnemyWhenThereIsTarget);
        }
        if (checkForCloseEnemyWhenThereIsNoTarget != null)
        {
            StopCoroutine(checkForCloseEnemyWhenThereIsNoTarget);
        }
        isCheckForEnemyWhenThereIsNoTargetTurnedOn = false;
        isCheckForEnemyWhenThereIsTargetTurnedOn = false;

        currentEnemyUnitBodyPart = null;
        if (weaponManager.AgentAimManager.IsAiming)
        {
            weaponManager.AgentAimManager.StopAiming();
            weaponManager.AgentAimManager.ClearTarget();
        }
    }

    public Goal GetCurrentGoal()
    {
        return currentGoal;
    }
    #endregion

    // Selection mark methods
    #region
    public void MarkAsSelected()
    {
        selectionProjector.SetActive(true);
    }

    public void MarkAsMainSelected()
    {
        mainSelectionProjector.SetActive(true);
    }

    public void MarkAsUnselected()
    {
        selectionProjector.SetActive(false);
        mainSelectionProjector.SetActive(false);
    }
    #endregion

    private void Update()
    {
        CurrentBehaviour();
    }

    private void CurrentBehaviour()
    {
        if (currentGoal != null)
        {
            if (currentGoal is MoveGoal)
            {
                MoveToDestination((MoveGoal)currentGoal);
            }
            else if (currentGoal is AttackGoal)
            {
                AttackAgent((AttackGoal)currentGoal);
            }
            else
            {
                currentGoal = null;
            }
        }
        else
        {
            SearchForEnemies();
        }
    }

    private void AttackAgent(AttackGoal attackGoal)
    {
        Debug.Log("Try to attack someone");
    }

    private void MoveToDestination(MoveGoal moveGoal)
    {
        aiPathHandler.destination = moveGoal.Destination;

        if (aiPathHandler.reachedDestination)
        {
            aiPathHandler.isStopped = true;
            currentGoal = null;
            StopCoroutine(checkEndPathCoroutine);
            Debug.Log("Reached move goal!");
        }
    }

    private void SearchForEnemies()
    {
        if (currentEnemyUnitBodyPart == null)
        {
            if (!isCheckForEnemyWhenThereIsNoTargetTurnedOn)
            {
                checkForCloseEnemyWhenThereIsNoTarget
                    = StartCoroutine(CheckForCloseEnemyAsync(checkForCloseEnemyWhenThereIsNoTargetPeriod));
                isCheckForEnemyWhenThereIsNoTargetTurnedOn = true;
            }

            if (weaponManager.AgentAimManager.IsAiming)
            {
                weaponManager.AgentAimManager.StopAiming();
                weaponManager.AgentAimManager.ClearTarget();
            }

            return;
        }

        if (!isCheckForEnemyWhenThereIsTargetTurnedOn)
        {
            checkForCloseEnemyWhenThereIsTarget
                = StartCoroutine(CheckForCloseEnemyAsync(checkForCloseEnemyWhenThereIsTargetPeriod));
            isCheckForEnemyWhenThereIsTargetTurnedOn = true;
        }

        if (!weaponManager.AgentAimManager.IsAiming)
        {
            weaponManager.AgentAimManager.StartAiming();
        }

        weaponManager.AgentAimManager.SetTarget(currentEnemyUnitBodyPart);

        if (weaponManager.AgentAimManager.IsTargetReachable(currentEnemyUnitBodyPart))
        {
            weaponManager.ActiveGun.Fire();
        }
    }

    IEnumerator CheckForCloseEnemyAsync(float period)
    {
        while (true)
        {
            Unit closestEnemy = eyeSightManager.GetClothestEnemyUnitInFieldOfView(lookDistance, controller.GetTeam());
            if (closestEnemy != null)
            {
                var enemyColliderCostPair = eyeSightManager.GetUnitsVisibleBodyPart(closestEnemy);
                if (enemyColliderCostPair != null)
                {
                    if (enemyColliderCostPair.collider.transform != currentEnemyUnitBodyPart)
                    {
                        currentEnemyUnitBodyPart = enemyColliderCostPair.collider.transform;
                        isCheckForEnemyWhenThereIsNoTargetTurnedOn = false;
                        isCheckForEnemyWhenThereIsTargetTurnedOn = false;
                        if (checkForCloseEnemyWhenThereIsTarget != null)
                        {
                            StopCoroutine(checkForCloseEnemyWhenThereIsTarget);
                        }
                        if (checkForCloseEnemyWhenThereIsNoTarget != null)
                        {
                            StopCoroutine(checkForCloseEnemyWhenThereIsNoTarget);
                        }
                        break;
                    }
                }
            }

            if (currentEnemyUnitBodyPart != null)
            {
                CheckMainTarget();
            }

            yield return new WaitForSeconds(period);
        }
    }

    private void CheckMainTarget()
    {
        Unit currentUnit = currentEnemyUnitBodyPart.GetComponent<Collider>().attachedRigidbody.GetComponent<Unit>();
        if (eyeSightManager.GetUnitsVisibleBodyPart(currentUnit) == null)
        {
            currentEnemyUnitBodyPart = null;
            isCheckForEnemyWhenThereIsTargetTurnedOn = false;
            if (checkForCloseEnemyWhenThereIsTarget != null)
            {
                StopCoroutine(checkForCloseEnemyWhenThereIsTarget);
            }
        }
    }

    IEnumerator CheckEndPathAsync()
    {
        previosCheckCoordinate = transform.position;
        yield return new WaitForSeconds(LevelManager.Instance.AgentsSecondsTillCheckEndPath);

        while ((previosCheckCoordinate - transform.position).magnitude > Mathf.Epsilon)
        {
            previosCheckCoordinate = transform.position;
            yield return new WaitForSeconds(LevelManager.Instance.AgentsSecondsTillCheckEndPath);
        }

        if (currentGoal is MoveGoal)
        {
            aiPathHandler.isStopped = true;
            currentGoal = null;
            Debug.Log("Reached move goal!"); ;
        }
    }

    private void OnDrawGizmosSelected()
    {
        Gizmos.color = Color.blue;
        Gizmos.DrawWireSphere(transform.position, lookDistance);
    }
}

Исходный код класса EyeSightManager:
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using System.Linq;

public class EyeSightManager : MonoBehaviour
{
    [SerializeField]
    Transform lookAroundPoint;

    [SerializeField]
    [Tooltip("Agents mask used to create raycast sphere")]
    LayerMask agentsMask;
    /// <summary>
    /// Returns the visible part with the highest prioraty of there is one
    /// </summary>
    /// <param name="unit"></param>
    /// <returns></returns>
    public ColliderCostPair GetUnitsVisibleBodyPart(Unit unit)
    {
        if (unit == null)
        {
            return null;
        }

        List<ColliderCostPair> unitsColliderCostPairs = unit.GetHitCollidersCosts();

        List<ColliderCostPair> colliderCostPairsInSight = unitsColliderCostPairs.FindAll((unitsColliderCostPair) =>
        {
            RaycastHit raycastHit;
            if (Physics.Raycast(lookAroundPoint.position, unitsColliderCostPair.collider.transform.position - lookAroundPoint.position, out raycastHit,
                Vector3.Distance(lookAroundPoint.position, unitsColliderCostPair.collider.transform.position)))
            {
                // Debug.DrawRay(lookAroundPoint.position, unitsColliderCostPair.collider.transform.position - lookAroundPoint.position, Color.white, 1f);
                if (raycastHit.collider.transform == unitsColliderCostPair.collider.transform)
                {
                    return true;
                }
            }

            return false;
        });

        if (colliderCostPairsInSight.Count == 0)
        {
            return null;
        }

        float maxPriority = colliderCostPairsInSight.Max(colliderCostPair => colliderCostPair.GetPriority());
        var maxPriorityColliderCostPair = colliderCostPairsInSight.First(colliderCostPair => colliderCostPair.GetPriority() == maxPriority);

        return maxPriorityColliderCostPair;
    }

    public List<Unit> GetEnemyUnitsInFieldOfView(float lookDistance, Team friendlyTeam)
    {
        Collider[] agentsColliders = Physics.OverlapSphere(transform.position, lookDistance, agentsMask);

        HashSet<Unit> enemyUnits = new HashSet<Unit>();

        foreach (Collider agentCollider in agentsColliders)
        {
            Agent agentInfo = agentCollider.attachedRigidbody.GetComponent<Agent>();

            if (agentInfo != null && agentInfo.GetController().GetTeam() != friendlyTeam)
            {
                if (GetUnitsVisibleBodyPart(agentInfo.SoldierBasic) != null)
                {
                    enemyUnits.Add(agentInfo.SoldierBasic);
                }
            }
        }

        return new List<Unit>(enemyUnits);
    }

    public List<Unit> GetEnemyUnitsInFieldOfViewOrderedByDistance(float lookDistance, Team friendlyTeam)
    {
        List<Unit> enemyUnitsList = GetEnemyUnitsInFieldOfView(lookDistance, friendlyTeam);

        enemyUnitsList.Sort((enemyUnit1, enemyUnit2) =>
        {
            return (enemyUnit1.transform.position - transform.position).magnitude
            .CompareTo((enemyUnit2.transform.position - transform.position).magnitude);
        });

        return enemyUnitsList;
    }

    public Unit GetClothestEnemyUnitInFieldOfView(float lookDistance, Team friendlyTeam)
    {
        List<Unit> enemyUnits = GetEnemyUnitsInFieldOfViewOrderedByDistance(lookDistance, friendlyTeam);

        if (enemyUnits.Count != 0)
        {
            return enemyUnits[0];
        }

        return null;
    }
}

Приложение B

Исходный код класса CommandsManager:
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using Sirenix.OdinInspector;
using System;

public class CommandsManager : MonoBehaviour
{
    [SerializeField]
    [Required]
    Camera playersCamera;

    [BoxGroup("Layer masks")]
    [Tooltip("Layers that are considered walkable by an agent")]
    [SerializeField]
    LayerMask walkableLayerMask;

    [BoxGroup("Layer masks")]
    [Tooltip("Layers that are considered attackable by an agent")]
    [SerializeField]
    LayerMask attackableLayerMask;

    [BoxGroup("Settings")]
    [SerializeField]
    [Tooltip("Max distance user can click on to command agent to do smth")]
    float commandDistance = 50;

    [BoxGroup("Settings")]
    [SerializeField]
    [Tooltip("Distance from ground that waves will be instantiated after click")]
    float clickWavesEffectGroundOffset = 0.05f;

    public Goal CurrentGoalToCommand { get; private set; }

    public void CheckCommands()
    {
        CurrentGoalToCommand = null;
        if (Input.GetMouseButtonUp(1))
        {
            CheckMoveCommand();
            CheckAttackCommand();
        }
    }

    private void CheckMoveCommand()
    {
        RaycastHit raycastHit;
        if (Physics.Raycast(playersCamera.ScreenPointToRay(Input.mousePosition), out raycastHit, commandDistance, walkableLayerMask))
        {
            ShowClickWavesEffects(raycastHit);
            CurrentGoalToCommand = new MoveGoal(raycastHit.point);
        }
    }

    private void CheckAttackCommand()
    {
        RaycastHit raycastHit;
        if (Physics.Raycast(playersCamera.ScreenPointToRay(Input.mousePosition), out raycastHit, commandDistance, attackableLayerMask))
        {
        }
    }

    private void ShowClickWavesEffects(RaycastHit raycastHit)
    {
        GameObject clickWavesEffectGameObject = PoolsManager.GetObjectPool(Poolskeys.clickEffectsPoolKey).GetObject();
        clickWavesEffectGameObject.transform.position = raycastHit.point + Vector3.up * clickWavesEffectGroundOffset;
        clickWavesEffectGameObject.transform.rotation = Quaternion.LookRotation(Vector3.up);
    }
}
    2
    
    
